{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np, pandas as pd, os\n",
      "from synthicity.utils import misc\n",
      "from drcog.models import regression_model_estimation, choice_model_estimation, dataset\n",
      "dset = dataset.DRCOGDataset(os.path.join(misc.data_dir(),'drcog.h5'))\n",
      "np.random.seed(1)\n",
      "\n",
      "##Variable Library\n",
      "from drcog.variables import variable_library\n",
      "variable_library.calculate_variables(dset)\n",
      "\n",
      "buildings = dset.fetch('buildings')[['building_type_id','improvement_value','land_area','non_residential_sqft','parcel_id','residential_units','sqft_per_unit','stories','tax_exempt','year_built','bldg_sq_ft','unit_price_non_residential','unit_price_residential','building_sqft_per_job','non_residential_units','base_year_jobs','all_units']]\n",
      "establishments = dset.fetch('establishments')\n",
      "del establishments['zone_id']\n",
      "del establishments['county_id']\n",
      "households = dset.fetch('households')\n",
      "del households['zone_id']\n",
      "del households['county_id']\n",
      "parcels = dset.fetch('parcels')\n",
      "zones = dset.fetch('zones')\n",
      "pz = pd.merge(parcels.reset_index(),zones,left_on='zone_id',right_index=True,how='left')\n",
      "pz = pz.set_index('parcel_id')\n",
      "bpz = pd.merge(buildings,pz,left_on='parcel_id',right_index=True)\n",
      "\n",
      "##Merge buildings and parcels\n",
      "buildings = pd.merge(buildings,parcels,left_on='parcel_id',right_index=True)\n",
      "\n",
      "##Merge households with bulidings/parcels\n",
      "households = pd.merge(households,buildings,left_on='building_id',right_index=True)\n",
      "\n",
      "##Merge establishments with bulidings/parcels\n",
      "establishments = pd.merge(establishments,buildings,left_on='building_id',right_index=True)\n",
      "\n",
      "#####Export jobs table\n",
      "e = establishments.reset_index()\n",
      "bids = []\n",
      "eids = []\n",
      "hbs = []\n",
      "sids = []\n",
      "for idx in e.index:\n",
      "    for job in range(e.employees[idx]):\n",
      "        bids.append(e.building_id[idx])\n",
      "        eids.append(e.index[idx])\n",
      "        hbs.append(e.home_based_status[idx])\n",
      "        sids.append(e.sector_id[idx])\n",
      "print len(bids)\n",
      "print len(eids)\n",
      "print len(hbs)\n",
      "print len(sids)\n",
      "jobs = pd.DataFrame({'job_id':range(1,len(bids)+1),'building_id':bids,'establishment_id':eids,'home_based_status':hbs,'sector_id':sids})\n",
      "jobs['parcel_id'] = bpz.parcel_id[jobs.building_id].values\n",
      "jobs['x'] = bpz.centroid_x[jobs.building_id].values\n",
      "jobs['y'] = bpz.centroid_y[jobs.building_id].values\n",
      "jobs['taz05_id'] = bpz.external_zone_id[jobs.building_id].values\n",
      "jobs['sector_id_six'] = 1*(jobs.sector_id==61) + 2*(jobs.sector_id==71) + 3*np.in1d(jobs.sector_id,[11,21,22,23,31,32,33,42,48,49]) + 4*np.in1d(jobs.sector_id,[7221,7222,7224]) + 5*np.in1d(jobs.sector_id,[44,45,7211,7212,7213,7223]) + 6*np.in1d(jobs.sector_id,[51,52,53,54,55,56,62,81,92])\n",
      "jobs['jobtypename'] = ''\n",
      "jobs.jobtypename[jobs.sector_id_six==1] = 'Education'\n",
      "jobs.jobtypename[jobs.sector_id_six==2] = 'Entertainment'\n",
      "jobs.jobtypename[jobs.sector_id_six==3] = 'Production'\n",
      "jobs.jobtypename[jobs.sector_id_six==4] = 'Restaurant'\n",
      "jobs.jobtypename[jobs.sector_id_six==5] = 'Retail'\n",
      "jobs.jobtypename[jobs.sector_id_six==6] = 'Service'\n",
      "jobs['urbancenter_id'] = 0\n",
      "del jobs['sector_id_six']\n",
      "del jobs['building_id']\n",
      "del jobs['establishment_id']\n",
      "del jobs['home_based_status']\n",
      "del jobs['sector_id']\n",
      "jobs.rename(columns={'job_id':'tempid'},inplace=True)\n",
      "#jobs.to_csv(tm_input_dir+'\\\\jobs%s.csv'%sim_year,index=False)\n",
      "\n",
      "#####Export household points\n",
      "hh = households[['building_id']].reset_index()\n",
      "hh['parcel_id'] = bpz.parcel_id[hh.building_id].values\n",
      "hh['x'] = bpz.centroid_x[hh.building_id].values\n",
      "hh['y'] = bpz.centroid_y[hh.building_id].values\n",
      "hh['taz05_id'] = bpz.external_zone_id[hh.building_id].values\n",
      "hh['dist_trans'] = np.minimum(bpz.dist_rail[hh.building_id].values, bpz.dist_bus[hh.building_id].values)/5280.0\n",
      "hh['urbancenter_id'] = 0\n",
      "hh_by_parcel = hh.groupby('parcel_id').size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching parcels\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching buildings"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching establishments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching households_for_estimation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table\n",
        "Fetching households\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching zones"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching travel_data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1605001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1605001\n",
        "1605001\n",
        "1605001\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parcel_coords = dset.parcel_coords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_parcels = parcels.index.values[parcels.parcel_sqft>= 435600]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_parcel_ids_with_hh = np.unique(hh.parcel_id[np.in1d(hh.parcel_id,big_parcels)].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(big_parcel_ids_with_hh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "9869"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for parcel_id in big_parcel_ids_with_hh:\n",
      "    idx_hh_on_parcel = np.in1d(hh.parcel_id,[parcel_id,])\n",
      "    coords = parcel_coords[parcel_coords.parcel_id==parcel_id]\n",
      "    idx_coord = np.random.choice(coords.index,size=idx_hh_on_parcel.sum(),replace=True)\n",
      "    x = coords.x.loc[idx_coord].values\n",
      "    y = coords.y.loc[idx_coord].values\n",
      "    hh.x[idx_hh_on_parcel] = x\n",
      "    hh.y[idx_hh_on_parcel] = y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_parcel_ids_with_jobs = np.unique(jobs.parcel_id[np.in1d(jobs.parcel_id,big_parcels)].values)\n",
      "print len(big_parcel_ids_with_jobs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3544\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for parcel_id in big_parcel_ids_with_jobs:\n",
      "    idx_jobs_on_parcel = np.in1d(jobs.parcel_id,[parcel_id,])\n",
      "    coords = parcel_coords[parcel_coords.parcel_id==parcel_id]\n",
      "    idx_coord = np.random.choice(coords.index,size=idx_jobs_on_parcel.sum(),replace=True)\n",
      "    x = coords.x.loc[idx_coord].values\n",
      "    y = coords.y.loc[idx_coord].values\n",
      "    jobs.x[idx_jobs_on_parcel] = x\n",
      "    jobs.y[idx_jobs_on_parcel] = y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}